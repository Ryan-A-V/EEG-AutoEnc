{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ../eegprep/sub-28/sub-28_task-fixthemix_eegprep.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 465922  =      0.000 ...  1863.688 secs...\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/1', 'Stimulus/11', 'Stimulus/12', 'Stimulus/13', 'Stimulus/15', 'Stimulus/2', 'Stimulus/21', 'Stimulus/22', 'Stimulus/23', 'Stimulus/25', 'Stimulus/3', 'Stimulus/31', 'Stimulus/32', 'Stimulus/33', 'Stimulus/35', 'Stimulus/41', 'Stimulus/42', 'Stimulus/43', 'Stimulus/45', 'Time 0/']\n",
      "{'New Segment/': 99999, 'Stimulus/1': 10001, 'Stimulus/11': 10002, 'Stimulus/12': 10003, 'Stimulus/13': 10004, 'Stimulus/15': 10005, 'Stimulus/2': 10006, 'Stimulus/21': 10007, 'Stimulus/22': 10008, 'Stimulus/23': 10009, 'Stimulus/25': 10010, 'Stimulus/3': 10011, 'Stimulus/31': 10012, 'Stimulus/32': 10013, 'Stimulus/33': 10014, 'Stimulus/35': 10015, 'Stimulus/41': 10016, 'Stimulus/42': 10017, 'Stimulus/43': 10018, 'Stimulus/45': 10019, 'Time 0/': 10020}\n"
     ]
    }
   ],
   "source": [
    "#Load EEG data - preprocessed\n",
    "import mne\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Subject numbers and experiment\n",
    "sub = \"sub-28\"\n",
    "exp = \"fixthemix\"\n",
    "\n",
    "fname = f\"../eegprep/{sub}/{sub}_task-{exp}_eegprep.vhdr\"\n",
    "raw = mne.io.read_raw_brainvision(fname, preload=True)\n",
    "events, event_dict = mne.events_from_annotations(raw)\n",
    "#start of songs in sample numbers\n",
    "song_starts = np.array(events)[events[:,2] == 10001][2:,0]\n",
    "press_starts = []\n",
    "press_starts = events[2:,0]\n",
    "\n",
    "print(event_dict)\n",
    "#set sample rate\n",
    "sample_rate = 250\n",
    "#raw.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82188285, 2)\n",
      "(31, 465923)\n",
      "[1.18953327e-04 6.59490184e-05 1.18926387e-04 ... 6.60010739e-05\n",
      " 1.18980289e-04 6.59749977e-05]\n",
      "1.1351156664279438 6.148384151114298e-05\n"
     ]
    }
   ],
   "source": [
    "#Load FLAC Audio in\n",
    "import pyflac\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as sig\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "aname = f\"../audio/{sub}/{sub}_task-{exp}_aud.flac\"\n",
    "decoder = pyflac.FileDecoder(aname)\n",
    "audio, samp_rate = decoder.process()\n",
    "print(audio.shape)\n",
    "print(raw.get_data().shape)\n",
    "\n",
    "#Resample audio to EEG sample rate and get audio envelope\n",
    "audio = sig.resample(audio, raw.get_data().shape[1])\n",
    "audio = np.abs(sig.hilbert(audio.T))\n",
    "audio = np.average(audio, axis=0)\n",
    "print(audio)\n",
    "print(np.max(audio), np.min(audio))\n",
    "\n",
    "# #normalize audio\n",
    "# scaler = StandardScaler()\n",
    "# audio = scaler.fit_transform(audio.reshape(-1,1)).reshape(1, -1)\n",
    "# print(audio)\n",
    "# print(np.max(audio), np.min(audio))\n",
    "# print(np.mean(audio), np.std(audio))\n",
    "\n",
    "audio = np.atleast_2d(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS\n",
    "#================\n",
    "\n",
    "def split_events(X, Y, events, sample_rate, bound):\n",
    "\n",
    "    new_X = []\n",
    "    new_Y = []\n",
    "\n",
    "    for event in events:\n",
    "        new_X.append(X[:,event - (sample_rate*bound):event + (sample_rate*bound)])\n",
    "        new_Y.append(Y[:,event - (sample_rate*bound):event + (sample_rate*bound)])\n",
    "\n",
    "    return new_X, new_Y\n",
    "\n",
    "\n",
    "\n",
    "#Build regression matrix\n",
    "#Adapted from https://stackoverflow.com/questions/5842903/block-tridiagonal-matrix-python \n",
    "from scipy.sparse import diags\n",
    "import numpy as np\n",
    "fs = 250\n",
    "\n",
    "#lag_mat takes a given input (stimulus) and generates a time-lagged matrix\n",
    "#currently set up only for the forward model\n",
    "def lag_mat(stimulus, sample_rate):\n",
    "\n",
    "    #sampling frequency\n",
    "    fs = sample_rate\n",
    "    #start and end in seconds * frequency = num of samples\n",
    "    start = int(np.floor(-0.25*fs))\n",
    "    end = int(np.ceil(0.85*fs))\n",
    "\n",
    "    #time lag list - sample points for the time lags\n",
    "    lags = list(range(int(np.floor(-0.25 * fs)), int(np.ceil(0.85 * fs)) + 1))\n",
    "    n_lags = len(lags)\n",
    "\n",
    "    #Adapted from https://github.com/powerfulbean/mTRFpy/blob/master/mtrf/matrices.py\n",
    "    x = np.array([stimulus]).T\n",
    "    n_samples, n_variables = x.shape\n",
    "    if max(lags) > n_samples:\n",
    "        raise ValueError(\"The maximum lag can't be longer than the signal!\")\n",
    "    lag_matrix = np.zeros((n_samples, n_variables * n_lags))\n",
    "\n",
    "    for idx, lag in enumerate(lags):\n",
    "        col_slice = slice(idx * n_variables, (idx + 1) * n_variables)\n",
    "        if lag < 0:\n",
    "            lag_matrix[0 : n_samples + lag, col_slice] = x[-lag:, :]\n",
    "        elif lag > 0:\n",
    "            lag_matrix[lag:n_samples, col_slice] = x[0 : n_samples - lag, :]\n",
    "        else:\n",
    "            lag_matrix[:, col_slice] = x\n",
    "\n",
    "\n",
    "    return lag_matrix\n",
    "\n",
    "\n",
    "#generate mask for empty portions of data at end of songs\n",
    "#stimulus should be given as 1-D\n",
    "#threshold gives the maximum amplitude of the audio envelope to be considered as\n",
    "#\"no audio\"\n",
    "#minimum gives the number of sample points to be under this threshold for the\n",
    "#current section of the song to be considered the end\n",
    "def mask(stimulus, threshold, minimum):\n",
    "    n_samples = len(stimulus)\n",
    "    song_mask = np.ones(n_samples)\n",
    "    min_num = minimum\n",
    "    thresh = threshold\n",
    "    zeros = 0\n",
    "    num=0\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        if np.abs(stimulus[sample]) <= thresh:\n",
    "            zeros += 1\n",
    "            if zeros == min_num:\n",
    "                song_mask[sample-min_num-1:n_samples] = np.zeros(n_samples - (sample - min_num-1))\n",
    "                zeros=0\n",
    "                num+=1\n",
    "                break\n",
    "        else:\n",
    "            zeros = 0\n",
    "\n",
    "\n",
    "    return song_mask\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy.sparse import diags\n",
    "import random\n",
    "\n",
    "#split input data into epochs\n",
    "#give to function as 2d array at the minimum where each column is a sample point\n",
    "#benchmarks should be a list of sample points\n",
    "def split(data, benchmarks):\n",
    "    n_samples = data.shape[-1]\n",
    "    songs = []\n",
    "    prev = 0\n",
    "    for song in benchmarks:\n",
    "        songs.append(data[:,prev:song])\n",
    "        prev = song\n",
    "\n",
    "    return songs\n",
    "\n",
    "#train the l2 model (from paper)\n",
    "#lam is the regularization parameter\n",
    "def train_l2(X, Y, lam, samp_rate):\n",
    "    n = (X.T@X).shape[0]\n",
    "    k = [-np.ones(n-1),2*np.ones(n),-np.ones(n-1)]\n",
    "    offset = [-1,0,1]\n",
    "    M = diags(k,offset).toarray()\n",
    "\n",
    "    M[0,0] -= 1\n",
    "    M[-1, -1] -= 1\n",
    "    M *= samp_rate\n",
    "\n",
    "    W = np.linalg.inv(X.T@X + lam*M)@(X.T@Y)*samp_rate\n",
    "    return W\n",
    "\n",
    "#perform cross validation on data\n",
    "#\n",
    "def cross_validation(X, Y, K=1, method='ridge', alpha=1., ratio=0.5):\n",
    "    scaler = StandardScaler()\n",
    "    fs = 250\n",
    "    assert method in ['ridge', 'l2', 'lasso', 'l1', 'elastic', 'elasticnet']\n",
    "\n",
    "    if type(alpha) != list:\n",
    "        alpha = [alpha]\n",
    "    if type(ratio) != list:\n",
    "        ratio = [ratio]\n",
    "\n",
    "\n",
    "    if method in ['ridge', 'l2']:\n",
    "\n",
    "        results = {f'{a}':None for a in alpha}\n",
    "\n",
    "        for val in alpha:\n",
    "\n",
    "            avg = []\n",
    "\n",
    "            #leave 1 out cross val\n",
    "            if False:\n",
    "                pass\n",
    "                num = K*-1\n",
    "                #shuffle data\n",
    "                ind = np.arange(len(X))\n",
    "                random.shuffle(ind)\n",
    "                X_shuffled = np.array(X)[ind]\n",
    "                Y_shuffled = np.array(Y)[ind]\n",
    "                \n",
    "                for i in range(len(X)):\n",
    "                    X_test = X_shuffled[i]\n",
    "                    X_shuffled\n",
    "                    \n",
    "\n",
    "\n",
    "            #regular K-fold cross val    \n",
    "            else:\n",
    "                #shuffle data\n",
    "                ind = np.arange(1,len(X)+1)\n",
    "                random.shuffle(ind)\n",
    "                X_shuffled = []\n",
    "                Y_shuffled = []\n",
    "                for i in ind:\n",
    "                    X_shuffled.append(X[f'song{i}'])\n",
    "                    Y_shuffled.append(Y[f'song{i}'])\n",
    "\n",
    "\n",
    "                #split data into K roughly even subsets\n",
    "                length = len(X_shuffled) // K\n",
    "                for i in range(length):\n",
    "                    X_test, Y_test, X_train, Y_train = [], [], [], []\n",
    "\n",
    "                    for j in range(len(X_shuffled)):\n",
    "                        if j in list(np.arange(i*K, (i+1)*K)):\n",
    "                            X_test.append(X_shuffled[j])\n",
    "                            Y_test.append(Y_shuffled[j].T)\n",
    "                        else:\n",
    "                            X_train.append(X_shuffled[j])\n",
    "                            Y_train.append(Y_shuffled[j].T)\n",
    "                    \n",
    "                   \n",
    "                    try:\n",
    "                        W = 0\n",
    "                        for j in range(len(X_train)):\n",
    "                            if type(W) == int:\n",
    "                                W = train_l2(X_train[j], Y_train[j], val, fs)\n",
    "                            else:\n",
    "                                W += train_l2(X_train[j], Y_train[j], val, fs)\n",
    "\n",
    "                        W = W/len(X_train)\n",
    "\n",
    "                        W = scaler.fit_transform(W)\n",
    "                        \n",
    "                        X_avg = 0\n",
    "                        Y_avg = 0\n",
    "\n",
    "                        for j in range(len(X_test)):\n",
    "                            if type(X_avg) == int:\n",
    "                                X_avg = X_test[j]\n",
    "                                Y_avg = Y_test[j]\n",
    "                            else:\n",
    "                                X_avg +=  X_test[j]\n",
    "                                Y_avg += Y_test[j]\n",
    "\n",
    "                        X_avg = X_avg/len(X_test)\n",
    "                        Y_avg = Y_avg/len(Y_test)\n",
    "\n",
    "                        X_avg = scaler.fit_transform(X_avg)\n",
    "                        Y_avg = scaler.fit_transform(Y_avg)\n",
    "\n",
    "                        Y_pred = X_avg@W\n",
    "                        avg.append(mean_squared_error(Y_avg, Y_pred))\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\nError {e} occurred in L2 with alpha = {val}\\n\")\n",
    "                        avg.append(np.inf)\n",
    "                \n",
    "                results[f'{val}'] = np.mean(avg)\n",
    "\n",
    "    if method in ['lasso',  'l1']:\n",
    "        \n",
    "        results = {f'{a}':None for a in alpha}\n",
    "\n",
    "        for val in alpha:\n",
    "\n",
    "            avg = []\n",
    "\n",
    "            #leave 1 out cross val\n",
    "            if False:\n",
    "                pass\n",
    "                num = K*-1\n",
    "                #shuffle data\n",
    "                ind = np.arange(len(X))\n",
    "                random.shuffle(ind)\n",
    "                X_shuffled = np.array(X)[ind]\n",
    "                Y_shuffled = np.array(Y)[ind]\n",
    "                \n",
    "                for i in range(len(X)):\n",
    "                    X_test = X_shuffled[i]\n",
    "                    X_shuffled\n",
    "                    \n",
    "\n",
    "\n",
    "            #regular K-fold cross val    \n",
    "            else:\n",
    "                #shuffle data\n",
    "                ind = np.arange(1,len(X)+1)\n",
    "                random.shuffle(ind)\n",
    "                X_shuffled = []\n",
    "                Y_shuffled = []\n",
    "                for i in ind:\n",
    "                    X_shuffled.append(X[f'song{i}'])\n",
    "                    Y_shuffled.append(Y[f'song{i}'])\n",
    "\n",
    "\n",
    "                #split data into K roughly even subsets\n",
    "                length = len(X_shuffled) // K\n",
    "                for i in range(length):\n",
    "                    X_test, Y_test, X_train, Y_train = [], [], [], []\n",
    "\n",
    "                    for j in range(len(X_shuffled)):\n",
    "                        if j in list(np.arange(i*K, (i+1)*K)):\n",
    "                            X_test.extend(X_shuffled[j])\n",
    "                            Y_test.extend(Y_shuffled[j].T)\n",
    "                        else:\n",
    "                            X_train.extend(X_shuffled[j])\n",
    "                            Y_train.extend(Y_shuffled[j].T)\n",
    "                    \n",
    "                    X_train = np.array(X_train)\n",
    "                    X_test = np.array(X_test)\n",
    "                    Y_train = np.array(Y_train)\n",
    "                    Y_test = np.array(Y_test)\n",
    "                    try:\n",
    "                        model = Lasso(alpha=val)\n",
    "                        model.fit(X_train, Y_train)\n",
    "                        Y_pred = model.predict(X_test)\n",
    "                        avg.append(mean_squared_error(Y_test, Y_pred))\n",
    "                    except Exception as e:\n",
    "                        print(f'\\nError {e} occurred in L1 with alpha = {val}\\n')\n",
    "                        avg.append(np.inf)\n",
    "                \n",
    "                results[f'{val}'] = np.mean(avg)\n",
    "\n",
    "\n",
    "\n",
    "    if method in ['elastic', 'elasticnet']:\n",
    "\n",
    "        results = {f'{a}, {b}':None for a in alpha for b in ratio}\n",
    "\n",
    "        for a in alpha:\n",
    "            for b in ratio:\n",
    "                avg = []\n",
    "\n",
    "                #leave 1 out cross val\n",
    "                if False:\n",
    "                    pass\n",
    "                    num = K*-1\n",
    "                    #shuffle data\n",
    "                    ind = np.arange(len(X))\n",
    "                    random.shuffle(ind)\n",
    "                    X_shuffled = np.array(X)[ind]\n",
    "                    Y_shuffled = np.array(Y)[ind]\n",
    "                    \n",
    "                    for i in range(len(X)):\n",
    "                        X_test = X_shuffled[i]\n",
    "                        X_shuffled\n",
    "                        \n",
    "\n",
    "\n",
    "                #regular K-fold cross val    \n",
    "                else:\n",
    "                    #shuffle data\n",
    "                    ind = np.arange(1,len(X)+1)\n",
    "                    random.shuffle(ind)\n",
    "                    X_shuffled = []\n",
    "                    Y_shuffled = []\n",
    "                    for i in ind:\n",
    "                        X_shuffled.append(X[f'song{i}'])\n",
    "                        Y_shuffled.append(Y[f'song{i}'])\n",
    "\n",
    "\n",
    "                    #split data into K roughly even subsets\n",
    "                    length = len(X_shuffled) // K\n",
    "                    for i in range(length):\n",
    "                        X_test, Y_test, X_train, Y_train = [], [], [], []\n",
    "\n",
    "                        for j in range(len(X_shuffled)):\n",
    "                            if j in list(np.arange(i*K, (i+1)*K)):\n",
    "                                X_test.extend(X_shuffled[j])\n",
    "                                Y_test.extend(Y_shuffled[j].T)\n",
    "                            else:\n",
    "                                X_train.extend(X_shuffled[j])\n",
    "                                Y_train.extend(Y_shuffled[j].T)\n",
    "                        \n",
    "                        X_train = np.array(X_train)\n",
    "                        X_test = np.array(X_test)\n",
    "                        Y_train = np.array(Y_train)\n",
    "                        Y_test = np.array(Y_test)\n",
    "                        try:\n",
    "                            model = ElasticNet(alpha=a, l1_ratio=b)\n",
    "                            model.fit(X_train, Y_train)\n",
    "                            Y_pred = model.predict(X_test)\n",
    "                            avg.append(mean_squared_error(Y_test, Y_pred))\n",
    "                        except Exception as e:\n",
    "                            print(f'\\nError {e} occurred in elasticnet with values alpha={a} and ratio={b}\\n')\n",
    "                    \n",
    "                    results[f'{a}, {b}'] = np.mean(avg)\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def train(X, Y, method='ridge', alpha=1., ratio=0.5, sample_rate=250):\n",
    "    X_train, Y_train = X, Y\n",
    "\n",
    "    fs = sample_rate\n",
    "    \n",
    "    if method in ['custom']:\n",
    "\n",
    "        W_s = [train_l2(X_train[i], Y_train[i], alpha, fs) for i in range(len(X_train))]\n",
    "        W = None\n",
    "        for i in W_s:\n",
    "            W = (W + i if not(W is None) else i)\n",
    "\n",
    "        W = W/len(W_s)\n",
    "\n",
    "    if method in ['ridge',  'l2']:\n",
    "        model = Ridge(alpha=alpha)\n",
    "\n",
    "        W_s = []\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            model.fit(X_train[i], Y_train[i])\n",
    "            W_s.append(model.coef_.T)\n",
    "\n",
    "        W = None\n",
    "        for i in W_s:\n",
    "            W = (W + i if not(W is None) else i)\n",
    "\n",
    "        W = W/len(W_s)\n",
    "\n",
    "    if method in ['lasso',  'l1']:\n",
    "        model = Lasso(alpha=alpha)\n",
    "\n",
    "        W_s = []\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            model.fit(X_train[i], Y_train[i])\n",
    "            W_s.append(model.coef_.T)\n",
    "\n",
    "        W = None\n",
    "        for i in W_s:\n",
    "            W = (W + i if not(W is None) else i)\n",
    "\n",
    "        W = W/len(W_s)\n",
    "\n",
    "    if method in ['elastic', 'elasticnet', 'elastic-net']:\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=ratio)\n",
    "\n",
    "        W_s = []\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            model.fit(X_train[i], Y_train[i])\n",
    "            W_s.append(model.coef_.T)\n",
    "\n",
    "        W = None\n",
    "        for i in W_s:\n",
    "            W = (W + i if not(W is None) else i)\n",
    "\n",
    "        W = W/len(W_s)\n",
    "\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.902150943766495e-05\n",
      "59010\n",
      "49021\n",
      "48761\n",
      "54833\n",
      "63586\n"
     ]
    }
   ],
   "source": [
    "#SPLIT BY SONG\n",
    "\n",
    "#Split audio and eeg up into their corresponding songs\n",
    "#note that the 1st elements are the whitespace before the first song starts\n",
    "\n",
    "split_eeg = scaler.fit_transform(raw.get_data().T).T\n",
    "\n",
    "split_audio = split(audio, song_starts)\n",
    "split_eeg = split(split_eeg, song_starts)\n",
    "\n",
    "fs = sample_rate\n",
    "\n",
    "labels = [f'song{i}' for i in range(1, len(split_audio))]\n",
    "labels_train, labels_test = train_test_split(labels, train_size=0.8, test_size=0.2, random_state=5)\n",
    "\n",
    "\n",
    "print(np.min(split_audio[2]))\n",
    "\n",
    "#X and Y are dictionaries so that the ordering of the corresponding segments can\n",
    "#be maintained\n",
    "X = {}\n",
    "Y = {}\n",
    "for i in range(1,len(split_audio)):\n",
    "    #X gets masked here (remove white space at end of songs)\n",
    "    print(len(split_audio[i][0]))\n",
    "    #X[f'song{i}'] = np.atleast_2d(mask(split_audio[i][0], 0.9, 5000)).T * lag_mat(split_audio[i][0], fs)\n",
    "    X[f'song{i}'] = split_audio[i][0]\n",
    "\n",
    "    Y[f'song{i}'] = split_eeg[i]\n",
    "\n",
    "X_test, X_train, Y_test, Y_train = [],[],[],[]\n",
    "\n",
    "for i in labels_train:\n",
    "    X_train.append(X[i])\n",
    "    Y_train.append(Y[i].T)\n",
    "\n",
    "for i in labels_test:\n",
    "    X_test.append(X[i])\n",
    "    Y_test.append(Y[i].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validating[##################################################] 5/5\n",
      "\n",
      "-0.016660000432654566\n"
     ]
    }
   ],
   "source": [
    "from mtrf.model import TRF\n",
    "from mtrf.stats import neg_mse\n",
    "from mtrf.stats import crossval\n",
    "\n",
    "X_train.extend(X_test)\n",
    "Y_train.extend(Y_test)\n",
    "\n",
    "bwd_trf = TRF(direction=-1, metric=neg_mse)\n",
    "bwd_trf.train(X_train,Y_train, 250, -200/1000, 800/1000, 1000)\n",
    "mse_bwd = crossval(bwd_trf, X_train, Y_train, 250, -200/1000, 800/1000, 1000)\n",
    "print(mse_bwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Singular matrix for alpha = 1e+28 in custom\n",
      "Exception Singular matrix for alpha = 1e+29 in custom\n",
      "Custom Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 88.23268481390177\n",
      "alpha = 1000000.0: MSE = 88.1653888452273\n",
      "alpha = 10000000.0: MSE = 87.90322213489125\n",
      "alpha = 100000000.0: MSE = 86.46731511035654\n",
      "alpha = 1000000000.0: MSE = 78.88471091240343\n",
      "alpha = 10000000000.0: MSE = 61.18337888548214\n",
      "alpha = 100000000000.0: MSE = 46.903619455878484\n",
      "alpha = 1000000000000.0: MSE = 38.556275807683306\n",
      "alpha = 10000000000000.0: MSE = 29.991845199296737\n",
      "alpha = 100000000000000.0: MSE = 18.51889742129841\n",
      "alpha = 1000000000000000.0: MSE = 16.04657514335881\n",
      "alpha = 1e+16: MSE = 15.843239337975753\n",
      "alpha = 1e+17: MSE = 15.842603634697685\n",
      "alpha = 1e+18: MSE = 15.843068242288684\n",
      "alpha = 1e+19: MSE = 15.84312069511037\n",
      "alpha = 1e+20: MSE = 15.84312325966959\n",
      "alpha = 1e+21: MSE = 15.843125745282238\n",
      "alpha = 1e+22: MSE = 15.843047766258172\n",
      "alpha = 1.0000000000000001e+23: MSE = 15.843501604507571\n",
      "alpha = 1e+24: MSE = 15.834632720143933\n",
      "alpha = 1e+25: MSE = 16.183950036786086\n",
      "alpha = 1e+26: MSE = 16.328288158181376\n",
      "alpha = 1e+27: MSE = 17.450476333441532\n",
      "L2 Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 1.0044871116220884\n",
      "alpha = 1000000.0: MSE = 1.0044870959644239\n",
      "alpha = 10000000.0: MSE = 1.0044869396789158\n",
      "alpha = 100000000.0: MSE = 1.0044854030288153\n",
      "alpha = 1000000000.0: MSE = 1.0044714009098341\n",
      "alpha = 10000000000.0: MSE = 1.0043595677774595\n",
      "alpha = 100000000000.0: MSE = 1.0038394329301343\n",
      "alpha = 1000000000000.0: MSE = 1.0028950389983542\n",
      "alpha = 10000000000000.0: MSE = 1.0012878050764347\n",
      "alpha = 100000000000000.0: MSE = 1.0001404047214029\n",
      "alpha = 1000000000000000.0: MSE = 1.0000029144493554\n",
      "alpha = 1e+16: MSE = 0.9999998909546448\n",
      "alpha = 1e+17: MSE = 0.9999999841031\n",
      "alpha = 1e+18: MSE = 0.9999999983591685\n",
      "alpha = 1e+19: MSE = 0.9999999998354034\n",
      "alpha = 1e+20: MSE = 0.999999999983534\n",
      "alpha = 1e+21: MSE = 0.999999999998354\n",
      "alpha = 1e+22: MSE = 0.9999999999998355\n",
      "alpha = 1.0000000000000001e+23: MSE = 0.9999999999999829\n",
      "alpha = 1e+24: MSE = 0.9999999999999966\n",
      "alpha = 1e+25: MSE = 1.0000000000000002\n",
      "alpha = 1e+26: MSE = 0.9999999999999999\n",
      "alpha = 1e+27: MSE = 1.0\n",
      "alpha = 1e+28: MSE = 1.0\n",
      "alpha = 1e+29: MSE = 1.0\n",
      "\n",
      "L1 Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 1.0\n",
      "alpha = 1000000.0: MSE = 1.0\n",
      "alpha = 10000000.0: MSE = 1.0\n",
      "alpha = 100000000.0: MSE = 1.0\n",
      "alpha = 1000000000.0: MSE = 1.0\n",
      "alpha = 10000000000.0: MSE = 1.0\n",
      "alpha = 100000000000.0: MSE = 1.0\n",
      "alpha = 1000000000000.0: MSE = 1.0\n",
      "alpha = 10000000000000.0: MSE = 1.0\n",
      "alpha = 100000000000000.0: MSE = 1.0\n",
      "alpha = 1000000000000000.0: MSE = 1.0\n",
      "alpha = 1e+16: MSE = 1.0\n",
      "alpha = 1e+17: MSE = 1.0\n",
      "alpha = 1e+18: MSE = 1.0\n",
      "alpha = 1e+19: MSE = 1.0\n",
      "alpha = 1e+20: MSE = 1.0\n",
      "alpha = 1e+21: MSE = 1.0\n",
      "alpha = 1e+22: MSE = 1.0\n",
      "alpha = 1.0000000000000001e+23: MSE = 1.0\n",
      "alpha = 1e+24: MSE = 1.0\n",
      "alpha = 1e+25: MSE = 1.0\n",
      "alpha = 1e+26: MSE = 1.0\n",
      "alpha = 1e+27: MSE = 1.0\n",
      "alpha = 1e+28: MSE = 1.0\n",
      "alpha = 1e+29: MSE = 1.0\n",
      "Best Custom param: 1e+24 with score 15.834632720143933\n",
      "Best L2 param: 1e+16 with score 0.9999998909546448\n",
      "Best L1 param: 100000.0 with score 1.0\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "alphas = [10.**x for x in np.arange(5,30)]\n",
    "alphas = list(np.sort(alphas))\n",
    "ratios = [x/10 for x in np.arange(1,10, 2)]\n",
    "\n",
    "custom_res = {}\n",
    "l1_res = {}\n",
    "l2_res = {}\n",
    "elastic_res = {}\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "\n",
    "    try:\n",
    "        custom_res[f'{alpha}'] = train(X_train, Y_train, method = 'custom', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in custom\")\n",
    "        custom_res[f'{alpha}'] = None\n",
    "\n",
    "    try:\n",
    "        l2_res[f'{alpha}'] = train(X_train, Y_train, method = 'l2', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in l2\")\n",
    "        l2_res[f'{alpha}'] = None\n",
    "\n",
    "    try:\n",
    "        l1_res[f'{alpha}'] = train(X_train, Y_train, method = 'l1', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in l1\")\n",
    "        l1_res[f'{alpha}'] = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    for ratio in ratios:\n",
    "        try:\n",
    "            elastic_res[f'{alpha}-{ratio}'] = train(X_train, Y_train, method = 'elastic', alpha = alpha, ratio=ratio)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception {e} for alpha = {alpha} in elasticnet\")\n",
    "            elastic_res[f'{alpha}'] = None\n",
    "\n",
    "results = {'L1':{}, 'L2':{}, 'Elasticnet':{}, 'Custom':{}}\n",
    "\n",
    "\n",
    "best_custom = None\n",
    "best_custom_score = np.inf\n",
    "\n",
    "print(\"Custom Results:\\n\")\n",
    "for result in custom_res:\n",
    "    if not (custom_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@custom_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@custom_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['Custom'][result] = recon\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_custom is None:\n",
    "            best_custom = result\n",
    "            best_custom_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_custom_score > recon:\n",
    "                best_custom_score = recon\n",
    "                best_custom = result\n",
    "\n",
    "    else:\n",
    "        results['Custom'][result] = np.nan\n",
    "\n",
    "\n",
    "best_l2 = None\n",
    "best_l2_score = np.inf\n",
    "\n",
    "print(\"L2 Results:\\n\")\n",
    "for result in l2_res:\n",
    "    if not (l2_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@l2_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@l2_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['L2'][result] = recon\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_l2 is None:\n",
    "            best_l2 = result\n",
    "            best_l2_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_l2_score > recon:\n",
    "                best_l2_score = recon\n",
    "                best_l2 = result\n",
    "\n",
    "    else:\n",
    "        results['L2'][result] = np.nan\n",
    "\n",
    "best_l1 = None\n",
    "best_l1_score = np.inf\n",
    "\n",
    "print(\"\\nL1 Results:\\n\")\n",
    "for result in l1_res:\n",
    "    if not (l1_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@l1_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@l1_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['L1'][result] = recon\n",
    "\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_l1 is None:\n",
    "            best_l1 = result\n",
    "            best_l1_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_l1_score > recon:\n",
    "                best_l1_score = recon\n",
    "                best_l1 = result\n",
    "\n",
    "    else:\n",
    "        results['L1'][result] = np.nan\n",
    "\n",
    "best_elastic = None\n",
    "best_elastic_score = np.inf\n",
    "\n",
    "# print(\"\\nElastic Results:\\n\")\n",
    "# for result in elastic_res:\n",
    "#     if not (elastic_res[result] is None):\n",
    "#         recon = None\n",
    "#         for i in range(len(X_test)):\n",
    "#             recon = (recon + mean_squared_error(Y_test[i], X_test[i]@elastic_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@elastic_res[result]))\n",
    "\n",
    "#         recon = recon/len(X_test)\n",
    "#         results['Elasticnet'][result] = recon\n",
    "\n",
    "\n",
    "#         print(f'params = {result}: MSE = {recon}')\n",
    "\n",
    "#         if best_elastic is None:\n",
    "#             best_elastic = result\n",
    "#             best_elastic_score = recon\n",
    "\n",
    "#         else:\n",
    "#             if best_elastic_score > recon:\n",
    "#                 best_elastic_score = recon\n",
    "#                 best_elastic = result\n",
    "\n",
    "#     else:\n",
    "#         results['Elasticnet'][result] = np.nan\n",
    "\n",
    "\n",
    "print(f'Best Custom param: {best_custom} with score {best_custom_score}')\n",
    "print(f'Best L2 param: {best_l2} with score {best_l2_score}')\n",
    "print(f'Best L1 param: {best_l1} with score {best_l1_score}')\n",
    "# print(f'Best elastic param: {best_elastic} with score {best_elastic_score}')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "xs = np.log10(alphas)\n",
    "series1 = np.array(list(results['Custom'].values()))\n",
    "series2 = np.array(list(results['L1'].values()))\n",
    "series3 = np.array(list(results['L2'].values()))\n",
    "\n",
    "mask1 = np.isfinite(series1)\n",
    "mask2 = np.isfinite(series2)\n",
    "mask3 = np.isfinite(series3)\n",
    "\n",
    "plt.plot(xs[mask1], series1[mask1], color='g', label=\"Quadratic\")\n",
    "plt.plot(xs[mask2], series2[mask2], color='b', label=\"L1\")\n",
    "plt.plot(xs[mask3], series3[mask3], color='r', label=\"L2\")\n",
    "plt.xlabel('Regularization Value (Exponent)')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title('L1, L2, and Quadratic Regularization MSE Scores (Songs)')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(list(results['Elasticnet'].keys()), list(results['Elasticnet'].values()), '.')\n",
    "# plt.xlabel(\"Parameters (Regularization Constant-L1 Ratio)\")\n",
    "# plt.ylabel(\"MSE\")\n",
    "# plt.title('Elasticnet Regularization MSE Scores')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.0165403 ,  0.01973611,  0.00970279, ...,  0.0183209 ,\n",
      "         0.01300594,  0.02086175],\n",
      "       [ 0.01658135,  0.01972791,  0.00984719, ...,  0.0183296 ,\n",
      "         0.01309058,  0.02083784],\n",
      "       [ 0.01684131,  0.01999628,  0.01008715, ...,  0.01859066,\n",
      "         0.0133336 ,  0.02110997],\n",
      "       ...,\n",
      "       [-0.0046927 , -0.00553786, -0.00288489, ..., -0.00515598,\n",
      "        -0.00374457, -0.00584064],\n",
      "       [-0.00481902, -0.00565923, -0.00301439, ..., -0.00528149,\n",
      "        -0.003872  , -0.00596055],\n",
      "       [-0.00483857, -0.00568529, -0.00302633, ..., -0.00530054,\n",
      "        -0.00388424, -0.00598928]])]\n",
      "1\n",
      "index 31 is out of bounds for axis 1 with size 31\n",
      "index 31 is out of bounds for axis 1 with size 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malco\\AppData\\Local\\Temp\\ipykernel_44348\\1951856655.py:45: MatplotlibDeprecationWarning: You have mixed positional and keyword arguments, some input may be discarded.  This is deprecated since 3.9 and will become an error in 3.11.\n",
      "  fig.legend([dummy0, dummy1], labels=[\"Reconstructed\", \"Actual\"], loc='upper right')\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ind = 0\n",
    "\n",
    "valW = scaler.fit_transform(custom_res[best_custom])\n",
    "\n",
    "recon = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    recon.append(scaler.fit_transform(X_test[i]@valW))\n",
    "\n",
    "print(recon)\n",
    "print(len(recon))\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "plt.suptitle(\"All Channels of TRF (Averaged Over Each Song in Test Set)\")\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        try:\n",
    "            axs[i, j].plot(np.linspace(-0.25, 0.85, valW.shape[0]), valW[:,(i*8) + j])\n",
    "            #axs[i, j].plot(np.linspace(-0.25, 0.85, model.coef_.shape[0]), model.coef_[:,(i*8) + j])\n",
    "\n",
    "        except Exception as e:\n",
    "            axs[i, j].plot(np.linspace(-0.25,0.85, valW.shape[0]), valW)\n",
    "            print(f\"{e}\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "plt.suptitle(f\"All Channels of Reconstructed EEG Data Compared with Actual EEG Data\")\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        try:\n",
    "            axs[i, j].plot(recon[ind][:,(i*8) + j],  color='blue')\n",
    "            #axs[i, j].plot(models[0].predict(X['song3'])[:,(i*8) + j])\n",
    "\n",
    "            axs[i,j].plot(Y_test[ind].T[(i*8) + j], alpha=0.5, color='red')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            dummy0=axs[i, j].plot(recon[ind][:,0], label = \"Reconstructed\", color=\"blue\")\n",
    "            dummy1=axs[i, j].plot(recon[ind][:,0], label=\"Actual\", color='red')\n",
    "\n",
    "            fig.legend([dummy0, dummy1], labels=[\"Reconstructed\", \"Actual\"], loc='upper right')\n",
    "\n",
    "            for a in dummy0:\n",
    "                a.set_visible(False)\n",
    "\n",
    "            for a in dummy1:\n",
    "                a.set_visible(False)\n",
    "\n",
    "            # axs[i,j].title.set_text(\"All Channels Of Reconstructed Data\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT BY SEGMENT\n",
    "\n",
    "#Split audio and eeg up into their corresponding songs\n",
    "#note that the 1st elements are the whitespace before the first song starts\n",
    "\n",
    "split_eeg = raw.get_data()\n",
    "times = np.linspace(song_starts[1], raw.get_data().shape[1], 300, dtype = int)\n",
    "split_audio, split_eeg = split_events(audio, split_eeg, times, 250, 5)\n",
    "\n",
    "fs = sample_rate\n",
    "\n",
    "labels = [f'song{i}' for i in range(1, len(split_audio))]\n",
    "labels_train, labels_test = train_test_split(labels, train_size=0.8, test_size=0.2, random_state=5)\n",
    "\n",
    "\n",
    "#X and Y are dictionaries so that the ordering of the corresponding segments can\n",
    "#be maintained\n",
    "X = {}\n",
    "Y = {}\n",
    "for i in range(1,len(split_audio)):\n",
    "    #X gets masked here (remove white space at end of songs)\n",
    "    X[f'song{i}'] = lag_mat(split_audio[i][0], fs)\n",
    "    #X[f'song{i}'] = lag_mat(split_audio[i][0], fs)\n",
    "\n",
    "    Y[f'song{i}'] = split_eeg[i]\n",
    "\n",
    "X_test, X_train, Y_test, Y_train = [],[],[],[]\n",
    "\n",
    "for i in labels_train:\n",
    "    X_train.append(X[i])\n",
    "    Y_train.append(scaler.fit_transform(Y[i].T))\n",
    "\n",
    "for i in labels_test:\n",
    "    X_test.append(X[i])\n",
    "    Y_test.append(scaler.fit_transform(Y[i].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Singular matrix for alpha = 1e+21 in custom\n",
      "Exception Singular matrix for alpha = 1e+22 in custom\n",
      "Exception Singular matrix for alpha = 1e+24 in custom\n",
      "Exception Singular matrix for alpha = 1e+25 in custom\n",
      "Exception Singular matrix for alpha = 1e+26 in custom\n",
      "Exception Singular matrix for alpha = 1e+28 in custom\n",
      "Exception Singular matrix for alpha = 1e+29 in custom\n",
      "ELASTIC\n",
      "Custom Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 627227.1012243597\n",
      "alpha = 1000000.0: MSE = 249671.9130058792\n",
      "alpha = 10000000.0: MSE = 133958.62552287147\n",
      "alpha = 100000000.0: MSE = 44302.3287912053\n",
      "alpha = 1000000000.0: MSE = 13414.634209086887\n",
      "alpha = 10000000000.0: MSE = 12164.00936773327\n",
      "alpha = 100000000000.0: MSE = 12051.606603858203\n",
      "alpha = 1000000000000.0: MSE = 11935.76400982187\n",
      "alpha = 10000000000000.0: MSE = 11870.22296449007\n",
      "alpha = 100000000000000.0: MSE = 11837.178521231946\n",
      "alpha = 1000000000000000.0: MSE = 11831.3214873692\n",
      "alpha = 1e+16: MSE = 11830.665879151931\n",
      "alpha = 1e+17: MSE = 11829.431043895778\n",
      "alpha = 1e+18: MSE = 11992.018139364856\n",
      "alpha = 1e+19: MSE = 12150.243186558966\n",
      "alpha = 1e+20: MSE = 12293.724288513318\n",
      "alpha = 1.0000000000000001e+23: MSE = 1917490.009521394\n",
      "alpha = 1e+27: MSE = 27068.30884018242\n",
      "L2 Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 52.188400688680595\n",
      "alpha = 1000000.0: MSE = 11.239920326737236\n",
      "alpha = 10000000.0: MSE = 3.7370384487012895\n",
      "alpha = 100000000.0: MSE = 1.2199977105680975\n",
      "alpha = 1000000000.0: MSE = 1.0399683063539091\n",
      "alpha = 10000000000.0: MSE = 1.0068756546351463\n",
      "alpha = 100000000000.0: MSE = 1.0048376081203214\n",
      "alpha = 1000000000000.0: MSE = 1.0006538661346243\n",
      "alpha = 10000000000000.0: MSE = 0.9999583185171185\n",
      "alpha = 100000000000000.0: MSE = 0.9999899549019008\n",
      "alpha = 1000000000000000.0: MSE = 0.9999988993291856\n",
      "alpha = 1e+16: MSE = 0.9999998889057784\n",
      "alpha = 1e+17: MSE = 0.9999999888802363\n",
      "alpha = 1e+18: MSE = 0.99999999888792\n",
      "alpha = 1e+19: MSE = 0.9999999998887908\n",
      "alpha = 1e+20: MSE = 0.9999999999888787\n",
      "alpha = 1e+21: MSE = 0.999999999998888\n",
      "alpha = 1e+22: MSE = 0.9999999999998886\n",
      "alpha = 1.0000000000000001e+23: MSE = 0.999999999999989\n",
      "alpha = 1e+24: MSE = 0.9999999999999989\n",
      "alpha = 1e+25: MSE = 0.9999999999999999\n",
      "alpha = 1e+26: MSE = 1.0\n",
      "alpha = 1e+27: MSE = 1.0\n",
      "alpha = 1e+28: MSE = 1.0\n",
      "alpha = 1e+29: MSE = 1.0\n",
      "\n",
      "L1 Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 1.0\n",
      "alpha = 1000000.0: MSE = 1.0\n",
      "alpha = 10000000.0: MSE = 1.0\n",
      "alpha = 100000000.0: MSE = 1.0\n",
      "alpha = 1000000000.0: MSE = 1.0\n",
      "alpha = 10000000000.0: MSE = 1.0\n",
      "alpha = 100000000000.0: MSE = 1.0\n",
      "alpha = 1000000000000.0: MSE = 1.0\n",
      "alpha = 10000000000000.0: MSE = 1.0\n",
      "alpha = 100000000000000.0: MSE = 1.0\n",
      "alpha = 1000000000000000.0: MSE = 1.0\n",
      "alpha = 1e+16: MSE = 1.0\n",
      "alpha = 1e+17: MSE = 1.0\n",
      "alpha = 1e+18: MSE = 1.0\n",
      "alpha = 1e+19: MSE = 1.0\n",
      "alpha = 1e+20: MSE = 1.0\n",
      "alpha = 1e+21: MSE = 1.0\n",
      "alpha = 1e+22: MSE = 1.0\n",
      "alpha = 1.0000000000000001e+23: MSE = 1.0\n",
      "alpha = 1e+24: MSE = 1.0\n",
      "alpha = 1e+25: MSE = 1.0\n",
      "alpha = 1e+26: MSE = 1.0\n",
      "alpha = 1e+27: MSE = 1.0\n",
      "alpha = 1e+28: MSE = 1.0\n",
      "alpha = 1e+29: MSE = 1.0\n",
      "Best Custom param: 1e+17 with score 11829.431043895778\n",
      "Best L2 param: 10000000000000.0 with score 0.9999583185171185\n",
      "Best L1 param: 100000.0 with score 1.0\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "alphas = [10.**x for x in np.arange(5,30)]\n",
    "alphas = list(np.sort(alphas))\n",
    "ratios = [x/10 for x in np.arange(1,10, 2)]\n",
    "\n",
    "custom_res = {}\n",
    "l1_res = {}\n",
    "l2_res = {}\n",
    "elastic_res = {}\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "\n",
    "    try:\n",
    "        custom_res[f'{alpha}'] = train(X_train, Y_train, method = 'custom', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in custom\")\n",
    "        custom_res[f'{alpha}'] = None\n",
    "\n",
    "    try:\n",
    "        l2_res[f'{alpha}'] = train(X_train, Y_train, method = 'l2', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in l2\")\n",
    "        l2_res[f'{alpha}'] = None\n",
    "\n",
    "    try:\n",
    "        l1_res[f'{alpha}'] = train(X_train, Y_train, method = 'l1', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in l1\")\n",
    "        l1_res[f'{alpha}'] = None\n",
    "\n",
    "print(\"ELASTIC\")\n",
    "# for alpha in alphas:\n",
    "#     for ratio in ratios:\n",
    "#         try:\n",
    "#             elastic_res[f'{alpha}-{ratio}'] = train(X_train, Y_train, method = 'elastic', alpha = alpha, ratio=ratio)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Exception {e} for alpha = {alpha} in elasticnet\")\n",
    "#             elastic_res[f'{alpha}'] = None\n",
    "\n",
    "results = {'L1':{}, 'L2':{}, 'Elasticnet':{}, 'Custom':{}}\n",
    "\n",
    "\n",
    "best_custom = None\n",
    "best_custom_score = np.inf\n",
    "\n",
    "print(\"Custom Results:\\n\")\n",
    "for result in custom_res:\n",
    "    if not (custom_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@custom_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@custom_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['Custom'][result] = recon\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_custom is None:\n",
    "            best_custom = result\n",
    "            best_custom_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_custom_score > recon:\n",
    "                best_custom_score = recon\n",
    "                best_custom = result\n",
    "\n",
    "    else:\n",
    "        results['Custom'][result] = np.nan\n",
    "\n",
    "\n",
    "best_l2 = None\n",
    "best_l2_score = np.inf\n",
    "\n",
    "print(\"L2 Results:\\n\")\n",
    "for result in l2_res:\n",
    "    if not (l2_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@l2_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@l2_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['L2'][result] = recon\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_l2 is None:\n",
    "            best_l2 = result\n",
    "            best_l2_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_l2_score > recon:\n",
    "                best_l2_score = recon\n",
    "                best_l2 = result\n",
    "\n",
    "    else:\n",
    "        results['L2'][result] = np.nan\n",
    "\n",
    "best_l1 = None\n",
    "best_l1_score = np.inf\n",
    "\n",
    "print(\"\\nL1 Results:\\n\")\n",
    "for result in l1_res:\n",
    "    if not (l1_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@l1_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@l1_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['L1'][result] = recon\n",
    "\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_l1 is None:\n",
    "            best_l1 = result\n",
    "            best_l1_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_l1_score > recon:\n",
    "                best_l1_score = recon\n",
    "                best_l1 = result\n",
    "\n",
    "    else:\n",
    "        results['L1'][result] = np.nan\n",
    "\n",
    "best_elastic = None\n",
    "# best_elastic_score = np.inf\n",
    "\n",
    "# print(\"\\nElastic Results:\\n\")\n",
    "# for result in elastic_res:\n",
    "#     if not (elastic_res[result] is None):\n",
    "#         recon = None\n",
    "#         for i in range(len(X_test)):\n",
    "#             recon = (recon + mean_squared_error(Y_test[i], X_test[i]@elastic_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@elastic_res[result]))\n",
    "\n",
    "#         recon = recon/len(X_test)\n",
    "#         results['Elasticnet'][result] = recon\n",
    "\n",
    "\n",
    "#         print(f'params = {result}: MSE = {recon}')\n",
    "\n",
    "#         if best_elastic is None:\n",
    "#             best_elastic = result\n",
    "#             best_elastic_score = recon\n",
    "\n",
    "#         else:\n",
    "#             if best_elastic_score > recon:\n",
    "#                 best_elastic_score = recon\n",
    "#                 best_elastic = result\n",
    "\n",
    "#     else:\n",
    "#         results['Elasticnet'][result] = np.nan\n",
    "\n",
    "\n",
    "print(f'Best Custom param: {best_custom} with score {best_custom_score}')\n",
    "print(f'Best L2 param: {best_l2} with score {best_l2_score}')\n",
    "print(f'Best L1 param: {best_l1} with score {best_l1_score}')\n",
    "# print(f'Best elastic param: {best_elastic} with score {best_elastic_score}')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "xs = np.log10(alphas)\n",
    "series1 = np.array(list(results['Custom'].values()))\n",
    "series2 = np.array(list(results['L1'].values()))\n",
    "series3 = np.array(list(results['L2'].values()))\n",
    "\n",
    "mask1 = np.isfinite(series1)\n",
    "mask2 = np.isfinite(series2)\n",
    "mask3 = np.isfinite(series3)\n",
    "\n",
    "plt.plot(xs[mask1], series1[mask1], color='g', label=\"Quadratic\")\n",
    "plt.plot(xs[mask2], series2[mask2], color='b', label=\"L1\")\n",
    "plt.plot(xs[mask3], series3[mask3], color='r', label=\"L2\")\n",
    "plt.xlabel('Regularization Value (Exponent)')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title('L1, L2, and Quadratic Regularization MSE Scores (Segments)')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(list(results['Elasticnet'].keys()), list(results['Elasticnet'].values()), '.')\n",
    "# plt.xlabel(\"Parameters (Regularization Constant-L1 Ratio)\")\n",
    "# plt.ylabel(\"MSE\")\n",
    "# plt.title('Elasticnet Regularization MSE Scores')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 31 is out of bounds for axis 1 with size 31\n",
      "index 31 is out of bounds for axis 1 with size 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malco\\AppData\\Local\\Temp\\ipykernel_44348\\141820214.py:42: MatplotlibDeprecationWarning: You have mixed positional and keyword arguments, some input may be discarded.  This is deprecated since 3.9 and will become an error in 3.11.\n",
      "  fig.legend([dummy0, dummy1], labels=[\"Reconstructed\", \"Actual\"], loc='upper right')\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ind = 0\n",
    "\n",
    "valW = scaler.fit_transform(custom_res[best_custom])\n",
    "\n",
    "recon = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    recon.append(scaler.fit_transform(X_test[i]@valW))\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "plt.suptitle(\"All Channels of TRF (Averaged Over Each Segment in Test Set)\")\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        try:\n",
    "            axs[i, j].plot(np.linspace(-0.25, 0.85, valW.shape[0]), valW[:,(i*8) + j])\n",
    "            #axs[i, j].plot(np.linspace(-0.25, 0.85, model.coef_.shape[0]), model.coef_[:,(i*8) + j])\n",
    "\n",
    "        except Exception as e:\n",
    "            axs[i, j].plot(np.linspace(-0.25,0.85, valW.shape[0]), valW)\n",
    "            print(f\"{e}\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "plt.suptitle(f\"All Channels of Reconstructed EEG Data Compared with Actual EEG Data\")\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        try:\n",
    "            axs[i, j].plot(recon[ind][:,(i*8) + j],  color='blue')\n",
    "            #axs[i, j].plot(models[0].predict(X['song3'])[:,(i*8) + j])\n",
    "\n",
    "            axs[i,j].plot(Y_test[ind].T[(i*8) + j], alpha=0.5, color='red')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            dummy0=axs[i, j].plot(recon[ind][:,0], label = \"Reconstructed\", color=\"blue\")\n",
    "            dummy1=axs[i, j].plot(recon[ind][:,0], label=\"Actual\", color='red')\n",
    "\n",
    "            fig.legend([dummy0, dummy1], labels=[\"Reconstructed\", \"Actual\"], loc='upper right')\n",
    "\n",
    "            for a in dummy0:\n",
    "                a.set_visible(False)\n",
    "\n",
    "            for a in dummy1:\n",
    "                a.set_visible(False)\n",
    "\n",
    "            # axs[i,j].title.set_text(\"All Channels Of Reconstructed Data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#SPLIT BY EVENT\n",
    "\n",
    "#Split audio and eeg up into their corresponding songs\n",
    "#note that the 1st elements are the whitespace before the first song starts\n",
    "\n",
    "split_eeg = raw.get_data()\n",
    "\n",
    "split_audio, split_eeg = split_events(np.atleast_2d(audio), np.atleast_2d(split_eeg), press_starts, 250, 5)\n",
    "fs = sample_rate\n",
    "\n",
    "labels = [f'song{i}' for i in range(1, len(split_audio))]\n",
    "labels_train, labels_test = train_test_split(labels, train_size=0.8, test_size=0.2, random_state=5)\n",
    "\n",
    "\n",
    "#X and Y are dictionaries so that the ordering of the corresponding segments can\n",
    "#be maintained\n",
    "X = {}\n",
    "Y = {}\n",
    "for i in range(1,len(split_audio)):\n",
    "    X[f'song{i}'] = lag_mat(split_audio[i][0], fs)\n",
    "    Y[f'song{i}'] = split_eeg[i]\n",
    "\n",
    "X_test, X_train, Y_test, Y_train = [],[],[],[]\n",
    "\n",
    "for i in labels_train:\n",
    "    X_train.append(X[i])\n",
    "    Y_train.append(scaler.fit_transform(Y[i].T))\n",
    "\n",
    "for i in labels_test:\n",
    "    X_test.append(X[i])\n",
    "    Y_test.append(scaler.fit_transform(Y[i].T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Singular matrix for alpha = 1e+21 in custom\n",
      "Exception Singular matrix for alpha = 1e+22 in custom\n",
      "Exception Singular matrix for alpha = 1e+24 in custom\n",
      "Exception Singular matrix for alpha = 1e+25 in custom\n",
      "Exception Singular matrix for alpha = 1e+26 in custom\n",
      "Exception Singular matrix for alpha = 1e+28 in custom\n",
      "Exception Singular matrix for alpha = 1e+29 in custom\n",
      "Custom Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 194732.71058946548\n",
      "alpha = 1000000.0: MSE = 85491.64907918812\n",
      "alpha = 10000000.0: MSE = 29785.361538046564\n",
      "alpha = 100000000.0: MSE = 11710.703103343665\n",
      "alpha = 1000000000.0: MSE = 5815.048225382482\n",
      "alpha = 10000000000.0: MSE = 4121.656895005183\n",
      "alpha = 100000000000.0: MSE = 3583.7199018658657\n",
      "alpha = 1000000000000.0: MSE = 3103.6946794508794\n",
      "alpha = 10000000000000.0: MSE = 2822.8906074224487\n",
      "alpha = 100000000000000.0: MSE = 2808.8147225870007\n",
      "alpha = 1000000000000000.0: MSE = 2809.6345756300097\n",
      "alpha = 1e+16: MSE = 2809.755719491279\n",
      "alpha = 1e+17: MSE = 2809.8022501180835\n",
      "alpha = 1e+18: MSE = 2807.8972321449105\n",
      "alpha = 1e+19: MSE = 2839.7077362200766\n",
      "alpha = 1e+20: MSE = 2883.7314642569263\n",
      "alpha = 1.0000000000000001e+23: MSE = 402409.0526966171\n",
      "alpha = 1e+27: MSE = 41539.341928176626\n",
      "L2 Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 18.973639768671145\n",
      "alpha = 1000000.0: MSE = 7.1301083481658285\n",
      "alpha = 10000000.0: MSE = 2.453532635245067\n",
      "alpha = 100000000.0: MSE = 1.44135300583219\n",
      "alpha = 1000000000.0: MSE = 1.3088351878198132\n",
      "alpha = 10000000000.0: MSE = 1.2154287986778938\n",
      "alpha = 100000000000.0: MSE = 1.090494487482345\n",
      "alpha = 1000000000000.0: MSE = 1.0058648063503632\n",
      "alpha = 10000000000000.0: MSE = 0.9998547970098446\n",
      "alpha = 100000000000000.0: MSE = 0.9999712244135902\n",
      "alpha = 1000000000000000.0: MSE = 0.9999969649187123\n",
      "alpha = 1e+16: MSE = 0.9999996948989123\n",
      "alpha = 1e+17: MSE = 0.9999999694739431\n",
      "alpha = 1e+18: MSE = 0.9999999969472344\n",
      "alpha = 1e+19: MSE = 0.9999999996947214\n",
      "alpha = 1e+20: MSE = 0.9999999999694723\n",
      "alpha = 1e+21: MSE = 0.9999999999969471\n",
      "alpha = 1e+22: MSE = 0.9999999999996947\n",
      "alpha = 1.0000000000000001e+23: MSE = 0.9999999999999697\n",
      "alpha = 1e+24: MSE = 0.9999999999999969\n",
      "alpha = 1e+25: MSE = 0.9999999999999999\n",
      "alpha = 1e+26: MSE = 1.0\n",
      "alpha = 1e+27: MSE = 1.0\n",
      "alpha = 1e+28: MSE = 1.0\n",
      "alpha = 1e+29: MSE = 1.0\n",
      "\n",
      "L1 Results:\n",
      "\n",
      "alpha = 100000.0: MSE = 1.0\n",
      "alpha = 1000000.0: MSE = 1.0\n",
      "alpha = 10000000.0: MSE = 1.0\n",
      "alpha = 100000000.0: MSE = 1.0\n",
      "alpha = 1000000000.0: MSE = 1.0\n",
      "alpha = 10000000000.0: MSE = 1.0\n",
      "alpha = 100000000000.0: MSE = 1.0\n",
      "alpha = 1000000000000.0: MSE = 1.0\n",
      "alpha = 10000000000000.0: MSE = 1.0\n",
      "alpha = 100000000000000.0: MSE = 1.0\n",
      "alpha = 1000000000000000.0: MSE = 1.0\n",
      "alpha = 1e+16: MSE = 1.0\n",
      "alpha = 1e+17: MSE = 1.0\n",
      "alpha = 1e+18: MSE = 1.0\n",
      "alpha = 1e+19: MSE = 1.0\n",
      "alpha = 1e+20: MSE = 1.0\n",
      "alpha = 1e+21: MSE = 1.0\n",
      "alpha = 1e+22: MSE = 1.0\n",
      "alpha = 1.0000000000000001e+23: MSE = 1.0\n",
      "alpha = 1e+24: MSE = 1.0\n",
      "alpha = 1e+25: MSE = 1.0\n",
      "alpha = 1e+26: MSE = 1.0\n",
      "alpha = 1e+27: MSE = 1.0\n",
      "alpha = 1e+28: MSE = 1.0\n",
      "alpha = 1e+29: MSE = 1.0\n",
      "Best Custom param: 1e+18 with score 2807.8972321449105\n",
      "Best L2 param: 10000000000000.0 with score 0.9998547970098446\n",
      "Best L1 param: 100000.0 with score 1.0\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "alphas = [10.**x for x in np.arange(5,30)]\n",
    "alphas = list(np.sort(alphas))\n",
    "ratios = [x/10 for x in np.arange(1,10, 2)]\n",
    "\n",
    "custom_res = {}\n",
    "l1_res = {}\n",
    "l2_res = {}\n",
    "elastic_res = {}\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "\n",
    "    try:\n",
    "        custom_res[f'{alpha}'] = train(X_train, Y_train, method = 'custom', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in custom\")\n",
    "        custom_res[f'{alpha}'] = None\n",
    "\n",
    "    try:\n",
    "        l2_res[f'{alpha}'] = train(X_train, Y_train, method = 'l2', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in l2\")\n",
    "        l2_res[f'{alpha}'] = None\n",
    "\n",
    "    try:\n",
    "        l1_res[f'{alpha}'] = train(X_train, Y_train, method = 'l1', alpha = alpha)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e} for alpha = {alpha} in l1\")\n",
    "        l1_res[f'{alpha}'] = None\n",
    "\n",
    "# for alpha in alphas:\n",
    "#     for ratio in ratios:\n",
    "#         try:\n",
    "#             elastic_res[f'{alpha}-{ratio}'] = train(X_train, Y_train, method = 'elastic', alpha = alpha, ratio=ratio)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Exception {e} for alpha = {alpha} in elasticnet\")\n",
    "#             elastic_res[f'{alpha}'] = None\n",
    "\n",
    "results = {'L1':{}, 'L2':{}, 'Elasticnet':{}, 'Custom':{}}\n",
    "\n",
    "\n",
    "best_custom = None\n",
    "best_custom_score = np.inf\n",
    "\n",
    "print(\"Custom Results:\\n\")\n",
    "for result in custom_res:\n",
    "    if not (custom_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@custom_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@custom_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['Custom'][result] = recon\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_custom is None:\n",
    "            best_custom = result\n",
    "            best_custom_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_custom_score > recon:\n",
    "                best_custom_score = recon\n",
    "                best_custom = result\n",
    "\n",
    "    else:\n",
    "        results['Custom'][result] = np.nan\n",
    "\n",
    "\n",
    "best_l2 = None\n",
    "best_l2_score = np.inf\n",
    "\n",
    "print(\"L2 Results:\\n\")\n",
    "for result in l2_res:\n",
    "    if not (l2_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@l2_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@l2_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['L2'][result] = recon\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_l2 is None:\n",
    "            best_l2 = result\n",
    "            best_l2_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_l2_score > recon:\n",
    "                best_l2_score = recon\n",
    "                best_l2 = result\n",
    "\n",
    "    else:\n",
    "        results['L2'][result] = np.nan\n",
    "\n",
    "best_l1 = None\n",
    "best_l1_score = np.inf\n",
    "\n",
    "print(\"\\nL1 Results:\\n\")\n",
    "for result in l1_res:\n",
    "    if not (l1_res[result] is None):\n",
    "        recon = None\n",
    "        for i in range(len(X_test)):\n",
    "            recon = (recon + mean_squared_error(Y_test[i], X_test[i]@l1_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@l1_res[result]))\n",
    "\n",
    "        recon = recon/len(X_test)\n",
    "        results['L1'][result] = recon\n",
    "\n",
    "\n",
    "        print(f'alpha = {result}: MSE = {recon}')\n",
    "\n",
    "        if best_l1 is None:\n",
    "            best_l1 = result\n",
    "            best_l1_score = recon\n",
    "\n",
    "        else:\n",
    "            if best_l1_score > recon:\n",
    "                best_l1_score = recon\n",
    "                best_l1 = result\n",
    "\n",
    "    else:\n",
    "        results['L1'][result] = np.nan\n",
    "\n",
    "best_elastic = None\n",
    "best_elastic_score = np.inf\n",
    "\n",
    "# print(\"\\nElastic Results:\\n\")\n",
    "# for result in elastic_res:\n",
    "#     if not (elastic_res[result] is None):\n",
    "#         recon = None\n",
    "#         for i in range(len(X_test)):\n",
    "#             recon = (recon + mean_squared_error(Y_test[i], X_test[i]@elastic_res[result]) if not( recon is None ) else mean_squared_error(Y_test[i], X_test[i]@elastic_res[result]))\n",
    "\n",
    "#         recon = recon/len(X_test)\n",
    "#         results['Elasticnet'][result] = recon\n",
    "\n",
    "\n",
    "#         print(f'params = {result}: MSE = {recon}')\n",
    "\n",
    "#         if best_elastic is None:\n",
    "#             best_elastic = result\n",
    "#             best_elastic_score = recon\n",
    "\n",
    "#         else:\n",
    "#             if best_elastic_score > recon:\n",
    "#                 best_elastic_score = recon\n",
    "#                 best_elastic = result\n",
    "\n",
    "#     else:\n",
    "#         results['Elasticnet'][result] = np.nan\n",
    "\n",
    "\n",
    "print(f'Best Custom param: {best_custom} with score {best_custom_score}')\n",
    "print(f'Best L2 param: {best_l2} with score {best_l2_score}')\n",
    "print(f'Best L1 param: {best_l1} with score {best_l1_score}')\n",
    "#print(f'Best elastic param: {best_elastic} with score {best_elastic_score}')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "xs = np.log10(alphas)\n",
    "series1 = np.array(list(results['Custom'].values()))\n",
    "series2 = np.array(list(results['L1'].values()))\n",
    "series3 = np.array(list(results['L2'].values()))\n",
    "\n",
    "mask1 = np.isfinite(series1)\n",
    "mask2 = np.isfinite(series2)\n",
    "mask3 = np.isfinite(series3)\n",
    "\n",
    "plt.plot(xs[mask1], series1[mask1], color='g', label=\"Quadratic\")\n",
    "plt.plot(xs[mask2], series2[mask2], color='b', label=\"L1\")\n",
    "plt.plot(xs[mask3], series3[mask3], color='r', label=\"L2\")\n",
    "plt.xlabel('Regularization Value (Exponent)')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title('L1, L2, and Quadratic Regularization MSE Scores (Events)')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(list(results['Elasticnet'].keys()), list(results['Elasticnet'].values()), '.')\n",
    "# plt.xlabel(\"Parameters (Regularization Constant-L1 Ratio)\")\n",
    "# plt.ylabel(\"MSE\")\n",
    "# plt.title('Elasticnet Regularization MSE Scores')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 31 is out of bounds for axis 1 with size 31\n",
      "index 31 is out of bounds for axis 1 with size 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malco\\AppData\\Local\\Temp\\ipykernel_44348\\1101253276.py:42: MatplotlibDeprecationWarning: You have mixed positional and keyword arguments, some input may be discarded.  This is deprecated since 3.9 and will become an error in 3.11.\n",
      "  fig.legend([dummy0, dummy1], labels=[\"Reconstructed\", \"Actual\"], loc='upper right')\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ind = 0\n",
    "\n",
    "valW = scaler.fit_transform(custom_res[best_custom])\n",
    "\n",
    "recon = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    recon.append(scaler.fit_transform(X_test[i]@valW))\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "plt.suptitle(\"All Channels of TRF (Averaged Over Each Event in Test Set)\")\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        try:\n",
    "            axs[i, j].plot(np.linspace(-0.25, 0.85, valW.shape[0]), valW[:,(i*8) + j])\n",
    "            #axs[i, j].plot(np.linspace(-0.25, 0.85, model.coef_.shape[0]), model.coef_[:,(i*8) + j])\n",
    "\n",
    "        except Exception as e:\n",
    "            axs[i, j].plot(np.linspace(-0.25,0.85, valW.shape[0]), valW)\n",
    "            print(f\"{e}\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "plt.suptitle(f\"All Channels of Reconstructed EEG Data Compared with Actual EEG Data\")\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        try:\n",
    "            axs[i, j].plot(recon[ind][:,(i*8) + j],  color='blue')\n",
    "            #axs[i, j].plot(models[0].predict(X['song3'])[:,(i*8) + j])\n",
    "\n",
    "            axs[i,j].plot(Y_test[ind].T[(i*8) + j], alpha=0.5, color='red')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            dummy0=axs[i, j].plot(recon[ind][:,0], label = \"Reconstructed\", color=\"blue\")\n",
    "            dummy1=axs[i, j].plot(recon[ind][:,0], label=\"Actual\", color='red')\n",
    "\n",
    "            fig.legend([dummy0, dummy1], labels=[\"Reconstructed\", \"Actual\"], loc='upper right')\n",
    "\n",
    "            for a in dummy0:\n",
    "                a.set_visible(False)\n",
    "\n",
    "            for a in dummy1:\n",
    "                a.set_visible(False)\n",
    "\n",
    "            # axs[i,j].title.set_text(\"All Channels Of Reconstructed Data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
